{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c9cbed1-1bef-4bf3-8da1-3cd68f0deffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /root/miniconda3/envs/qa_transformer/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: transformers in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (4.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from requests->transformers) (2022.12.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b43f5a4-f46c-4512-a024-8e491ab482f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /root/miniconda3/envs/qa_transformer/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: datasets in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (2.14.2)\n",
      "Requirement already satisfied: aiohttp in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from datasets) (2.28.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: xxhash in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from datasets) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from datasets) (1.24.2)\n",
      "Requirement already satisfied: multiprocess in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: packaging in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: pandas in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m/bin/bash: /root/miniconda3/envs/qa_transformer/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: huggingface-hub in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (0.16.4)\n",
      "Requirement already satisfied: packaging>=20.9 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from huggingface-hub) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from huggingface-hub) (4.5.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from huggingface-hub) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from huggingface-hub) (5.4.1)\n",
      "Requirement already satisfied: fsspec in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from huggingface-hub) (2023.6.0)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from huggingface-hub) (3.12.2)\n",
      "Requirement already satisfied: requests in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from huggingface-hub) (2.28.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from requests->huggingface-hub) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from requests->huggingface-hub) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from requests->huggingface-hub) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (from requests->huggingface-hub) (3.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "730bd098-b4c6-491f-9b52-1c552cce7f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /root/miniconda3/envs/qa_transformer/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: cchardet in /root/miniconda3/envs/qa_transformer/lib/python3.9/site-packages (2.1.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install cchardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "758ac0d6-eda3-47b1-9bfc-bd05f43e6b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "datasets = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76886303-bdde-4486-b684-5e72409702a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '5733be284776f41900661182', 'title': 'University_of_Notre_Dame', 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}\n"
     ]
    }
   ],
   "source": [
    "print(datasets[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb527a88-8d75-4344-92d3-67c2794fd246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = 'distilbert-base-cased'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf8eb66-9ed7-46e9-8442-640495ee20ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 384 # max length of a feature - context or question\n",
    "doc_stride = (\n",
    "    128 # the overlap between 2 consecutive truncated responses\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc189c56-0e7f-4d0f-9ee0-d37c3b14a332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_features(examples):\n",
    "    # remove the white spaces from the exaple's question and context\n",
    "    \n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "    examples[\"context\"] = [c.lstrip() for c in examples[\"context\"]]\n",
    "    \n",
    "    # tokenize the examples using the tokenizer with the overflowing tokens creating a new sample with an overlap with the previous sample\n",
    "    \n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"context\"],\n",
    "        truncation=\"only_second\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    # stores the mapping from a feature to the corresponding example that it was part of after truncating\n",
    "    \n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    \n",
    "    # stores the starting and ending char position mapping for each token.\n",
    "    \n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "    \n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "    \n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # we will label impossible answers with the CLS token index\n",
    "        # impossible answer happens only when we have broken the context to multiple values (because of max length) and \n",
    "        # the answer does not lie in this portion of the brokem context \n",
    "        \n",
    "        # all the input ids in the tokenized examples\n",
    "        \n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        \n",
    "        # the index of the starting token in the tokenized input\n",
    "        \n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "        \n",
    "        # grab the sequence corresponding to that example (to know the context and the question)\n",
    "        \n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        \n",
    "        # one span of text from the context can be part of any example. the corresponding example is in the sample_mapping list\n",
    "        # [0, 0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 4, 5, 6, 7, 7, 7]\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[\"answers\"][sample_index]\n",
    "        \n",
    "        # if there are no answers to the question in the data file only then set the CLS as the answer\n",
    "        \n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            \n",
    "        else:\n",
    "            # check the starting and the end character index of the answer\n",
    "            \n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[\"text\"][0])\n",
    "            \n",
    "            # start and end token index of this part of span\n",
    "            \n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != 1:\n",
    "                token_start_index += 1\n",
    "                \n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != 1:\n",
    "                token_end_index -= 1\n",
    "                \n",
    "            \n",
    "            # detecting if the answer is out of this context, if yes then labeling the feature with CLS index\n",
    "            \n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "                \n",
    "            else:\n",
    "                # move the token_start_index and the token_end_index to the starting and the ending of the answer in the context\n",
    "                \n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                \n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index-1)\n",
    "                \n",
    "                while token_end_index >= 0 and offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                    \n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index+1)\n",
    "            \n",
    "            \n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97f2176c-da57-4865-9ece-1abb398b3dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = datasets.map(\n",
    "    prepare_train_features,\n",
    "    batched = True,\n",
    "    remove_columns=datasets['train'].column_names,\n",
    "    num_proc = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "384c197c-2265-46f8-8a6f-6ed0ce45d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tokenized_datasets['train'].with_format(\"numpy\")[:]\n",
    "validation_set = tokenized_datasets['validation'].with_format(\"numpy\")[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac9cc6eb-f18d-4dda-af8b-62b2e2f13cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 15:26:51.827796: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-31 15:26:52.385686: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/root/miniconda3/envs/qa_transformer/lib/\n",
      "2023-07-31 15:26:52.387646: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/root/miniconda3/envs/qa_transformer/lib/\n",
      "2023-07-31 15:26:52.387654: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-07-31 15:26:53.006841: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-31 15:26:53.021848: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-31 15:26:53.021906: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-31 15:26:53.022236: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-31 15:26:53.024206: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-31 15:26:53.024254: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-31 15:26:53.024289: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-31 15:26:53.446388: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-31 15:26:53.446489: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-31 15:26:53.446499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-07-31 15:26:53.446554: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-31 15:26:53.446585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7369 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0a:00.0, compute capability: 8.6\n",
      "2023-07-31 15:26:54.124534: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some layers from the model checkpoint at distilbert-base-cased were not used when initializing TFDistilBertForQuestionAnswering: ['vocab_layer_norm', 'vocab_transform', 'activation_13', 'vocab_projector']\n",
      "- This IS expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['qa_outputs', 'dropout_19']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForQuestionAnswering\n",
    "\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed4217f0-95d1-4078-890b-9e69b01d6ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "780f3f47-019e-4976-8129-63e6be847773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3080, compute capability 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 15:31:05.662532: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b04839e3-615e-4b5e-95a9-20fc69ef4866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 15:39:07.995155: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x6d7bcc10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-31 15:39:07.995182: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2023-07-31 15:39:07.998191: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-07-31 15:39:08.094824: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-07-31 15:39:08.168629: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5546/5546 [==============================] - 1047s 188ms/step - loss: 1.4951 - val_loss: 1.1651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f29202cea00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, validation_data = validation_set, batch_size = 16, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "de153a6a-7aab-4112-8d6c-b61ca5fb50af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 58\n"
     ]
    }
   ],
   "source": [
    "context = \"The discovery of the United States is a complex topic, largely because the land was already inhabited by diverse groups of indigenous peoples for thousands of years prior to the arrival of European explorers. However, in the context of European history, the discovery of America is typically attributed to the Italian explorer Christopher Columbus. Commissioned by the Spanish monarchy, Columbus set sail in 1492 hoping to find a new trade route to Asia. Instead, he landed in the Bahamas in the Caribbean, marking the first sustained encounter between the peoples of the Eastern and Western hemispheres and beginning a period of extensive European exploration and eventual colonization of the Americas.\"\n",
    "question = \"Who discovered america?\"\n",
    "\n",
    "inputs = tokenizer([context], [question], return_tensors=\"np\")\n",
    "outputs = model(inputs)\n",
    "start_position = tf.argmax(outputs.start_logits, axis=1)\n",
    "end_position = tf.argmax(outputs.end_logits, axis=1)\n",
    "print(int(start_position), int(end_position[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0ca477a5-217f-4383-a10a-227f6f2dec91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4978 8555]\n"
     ]
    }
   ],
   "source": [
    "answer = inputs[\"input_ids\"][0, int(start_position) : int(end_position) + 1]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df40e6b-cdc1-430b-aafc-16ac9107174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b7d4e375-8011-4b97-8a63-2cea35710b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b0882ec7044be8bdf057a99cbd1416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/sashakttripathi/transformers-question-answer/commit/f0d3665cfb4f10adc5b9003a3ac0d41aa751127b', commit_message='Upload tokenizer', commit_description='', oid='f0d3665cfb4f10adc5b9003a3ac0d41aa751127b', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"transformers-question-answer\", organization=\"sashakttripathi\")\n",
    "tokenizer.push_to_hub(\"transformers-question-answer\", organization=\"sashakttripathi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
